{"cells":[{"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n\n# Load the data\ncc_apps = pd.read_csv('cc_approvals.data', header=None) \ncc_apps.head()\n\n\n# Replace missing values\ncc_apps_cleaned = cc_apps.replace({'?':'np.NaN'})\n\ncc_apps_imputed = cc_apps_cleaned.copy()\n\nfor column in cc_apps_imputed.columns:\n    if cc_apps_imputed[column].dtype == 'object':\n        most_frequent_value = cc_apps_imputed[column].value_counts().idxmax()\n        cc_apps_imputed[column] = cc_apps_imputed[column].fillna(most_frequent_value)\n    else:\n        mean_value = cc_apps_imputed[column].mean()\n        cc_apps_imputed[column] = cc_apps_imputed[column].fillna(mean_value)\n\ncc_apps_dummies =  pd.get_dummies(cc_apps_imputed, drop_first = True)\n\n\n# Prepare the data for modeling\ntarget = cc_apps_dummies.iloc[:, -1].values  \nfeature = cc_apps_dummies.iloc[: ,:-1].values\n\nX_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state=42)\n\n\n# Scale data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)  \n\n\n# Train the model\nlog_reg = LogisticRegression()\n\nlog_reg.fit(X_train_scaled, y_train)\n\npredictions = log_reg.predict(X_train_scaled)\n\n\n# Find the best scoring model\ntolerance = [0.01, 0.001, 0.0001]\nmax_iteration = [100, 150, 200]\n\nparam_grid = dict(tol = tolerance, max_iter = max_iteration)\n\n\n# Create GridSearchCV object\ngrid_model = GridSearchCV(estimator = log_reg, param_grid = param_grid, cv = 5)\n\n\n# Fit the model\ngrid_model_result = grid_model.fit(X_train_scaled, y_train)\n\nbest_train_score, best_train_param = grid_model_result.best_score_, grid_model_result.best_params_\nprint(\"Best: %f using %s\" % (best_train_score, best_train_param))\n\n\n# Extract the best model\nbest_model = grid_model_result.best_estimator_\nbest_score = best_model.score(X_test_scaled, y_test)\n\nprint('Accuracy score:', best_score)\n\n\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":59,"type":"stream"}},"lastExecutedByKernel":null,"visualizeDataframe":false,"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"}},"id":"6e86b1e8-a3fa-4b09-982f-795f218bd1a6","cell_type":"code","execution_count":2,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}